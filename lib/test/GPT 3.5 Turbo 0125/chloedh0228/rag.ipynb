{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elija\\VSCodeLocal\\Learning\\Projects\\NLP\\AgenticInformationRetrieval\\env\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# required imports/libraries\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch import tensor\n",
    "from rouge_score import rouge_scorer\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain_pinecone import Pinecone\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .env file values \n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "openai_api_key = os.getenv('OPENAI_KEY')\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "pc_qa = os.getenv('PINECONE_QA')\n",
    "pc_context = os.getenv('PINECONE_CONTEXT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "autoModel = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_average(data):\n",
    "    bleu_scores = []\n",
    "    weights = (0.1, 0, 0, 0)  # Weights for uni-gram, bi-gram, tri-gram, and 4-gram\n",
    "    smooth_fn = SmoothingFunction().method1\n",
    "    references = np.array(data['Expected Answer'])\n",
    "    predictions = np.array(data['GPT Answer'])\n",
    "    \n",
    "    for index in range(len(references)):\n",
    "        \n",
    "        reference = references[index].split()\n",
    "        prediction = predictions[index].split()\n",
    "\n",
    "        score = sentence_bleu(reference, prediction, weights=weights, smoothing_function=smooth_fn)\n",
    "        # print(f'Score: {score}')\n",
    "        bleu_scores.append(score)\n",
    "\n",
    "    return np.mean(np.array(bleu_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_average(data):\n",
    "    rougeL_scores = []\n",
    "    rouge1_scores = []\n",
    "    weights = (0.1, 0, 0, 0)  # Weights for uni-gram, bi-gram, tri-gram, and 4-gram\n",
    "    smooth_fn = SmoothingFunction().method1\n",
    "    references = np.array(data['Expected Answer'])\n",
    "    predictions = np.array(data['GPT Answer'])\n",
    "    \n",
    "    for index in range(len(references)):\n",
    "        \n",
    "        reference = references[index]\n",
    "        prediction = predictions[index]\n",
    "\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(reference, prediction)\n",
    "        rouge1_scores.append(scores['rouge1'])\n",
    "        rougeL_scores.append(scores['rougeL'])\n",
    "        # print(f\"ROUGE-1 F1 Score: {scores['rouge1'].fmeasure:.2f}\")\n",
    "        # print(f\"ROUGE-L F1 Score: {scores['rougeL'].fmeasure:.2f}\")\n",
    "\n",
    "    return np.mean(np.array(rougeL_scores)), np.mean(np.array(rouge1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode a single string\n",
    "def encode_text(text):\n",
    "    # Tokenize the input text\n",
    "    encoded_input = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    \n",
    "    # Get the model output\n",
    "    with torch.no_grad():\n",
    "        output = autoModel(**encoded_input)\n",
    "    \n",
    "    # Use the mean pooling of token embeddings as the sentence embedding\n",
    "    sentence_embedding = output.last_hidden_state.mean(dim=1)\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elija\\AppData\\Local\\Temp\\ipykernel_24304\\1207440793.py:7: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.3 and will be removed in 1.0.0. Use :class:`~PineconeVectorStore` instead.\n",
      "  qaSearch = Pinecone(\n"
     ]
    }
   ],
   "source": [
    "# instantiate OpenAI client with API key\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "# initializing Pinecone vector databases instance\n",
    "qaSearch = Pinecone(\n",
    "    index_name=pc_qa,\n",
    "    embedding=OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    ")\n",
    "\n",
    "contextSearch = Pinecone(\n",
    "    index_name=pc_context,\n",
    "    embedding=OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appends one/few shot examples to evaluation prompt\n",
    "def few_shot(examples, evaluation_prompt):\n",
    "   for example in examples:\n",
    "       # separates example key and values\n",
    "       split_ex = example.split(' - ')\n",
    "       question = split_ex[0]\n",
    "       label = split_ex[1]\n",
    "       evaluation_prompt += '\\n\\nQuestion: \\\"' + question + \"\\\"\" + '\\n' + label\n",
    "\n",
    "   evaluation_prompt += '\\n\\nAnswer the following question:'\n",
    "   print(f'Finalized evaluation prompt... RAG complete!')\n",
    "\n",
    "   return evaluation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries vector database for custom,\n",
    "# with similar examples to user prompt\n",
    "def rag(text, question):\n",
    "    two_shots = []\n",
    "    # queries Pinecone database\n",
    "    print(f'Relevance Search...')\n",
    "    qa_results = qaSearch.max_marginal_relevance_search(text, k=3, fetch_k=10)\n",
    "    print(f'Finished querying!')\n",
    "    for i in range(len(qa_results)):\n",
    "        content = qa_results[i].page_content\n",
    "        # prevents repetition which will cause errors within OpenAI\n",
    "        two_shots.append(content)\n",
    "        # two valid examples found\n",
    "        if len(two_shots) == 2:\n",
    "            break\n",
    "    context_result = contextSearch.max_marginal_relevance_search(question, k=1, fetch_k=5)[0].page_content\n",
    "    print(f'Context Length: {len(context_result)}')\n",
    "    print(f'Context Value: {context_result}')\n",
    "    text += f'\\n\\nContext: {context_result}'\n",
    "    print(f'Appending shots...')\n",
    "    return few_shot(two_shots, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests accuracy of chosen model against unique prompt and data\n",
    "def evaluation(data, evaluation_prompt, model_name):\n",
    "\n",
    "    test = pd.DataFrame(columns=['Question', 'Expected Answer', 'GPT Answer', 'Similarity'])\n",
    "    for index, row in data.iterrows():\n",
    "        # Extract the question\n",
    "        question = row['Question']\n",
    "        expected_answer = row['Answer']\n",
    "\n",
    "        print(f\"Starting Completion at Index: {index}\")\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": rag(evaluation_prompt, question)\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": question\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        print(f'Finished Completion {index}!')\n",
    "        gpt_answer = completion.choices[0].message.content.strip()\n",
    "\n",
    "        # append results\n",
    "        test.loc[index] = [question, expected_answer, gpt_answer, None]\n",
    "\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAGAZINE NEWS NEW PRODUCTS TOPICS COLUMNS RESO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sacred Drift Earth Pilgrim London looking beau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David De Gea reassured Spain role Vicente Del ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elks Lodge Granite City Ill Gateway Heritage C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>youre paying good money wine able taste grapes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>Diyarbakır Metropolitan Municipality Water Sew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>Global Mapping SAC operating company globalmap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>Latest Mathematical analysis Stories Turbogene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>November 3 2010 111 Wow closet looks amazing W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>Cheers looking forward heres hoping weather ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Passage\n",
       "0      MAGAZINE NEWS NEW PRODUCTS TOPICS COLUMNS RESO...\n",
       "1      Sacred Drift Earth Pilgrim London looking beau...\n",
       "2      David De Gea reassured Spain role Vicente Del ...\n",
       "3      Elks Lodge Granite City Ill Gateway Heritage C...\n",
       "4      youre paying good money wine able taste grapes...\n",
       "...                                                  ...\n",
       "11995  Diyarbakır Metropolitan Municipality Water Sew...\n",
       "11996  Global Mapping SAC operating company globalmap...\n",
       "11997  Latest Mathematical analysis Stories Turbogene...\n",
       "11998  November 3 2010 111 Wow closet looks amazing W...\n",
       "11999  Cheers looking forward heres hoping weather ho...\n",
       "\n",
       "[12000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieves data to test accuracy against model of choice\n",
    "df_e = pd.read_csv('../../../data/validation/chloedh0228_evaluation_data.csv')\n",
    "df_c = pd.read_csv('../../../data/context/chloedh0228.csv')\n",
    "df_c = df_c.drop(columns=['Unnamed: 0'])\n",
    "df_e = df_e.drop(columns=['Unnamed: 0'])\n",
    "df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>projected growth rate global economy 2014 acco...</td>\n",
       "      <td>projected growth rate global economy 2014 acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terminated relationships Paula Deen scandalous...</td>\n",
       "      <td>Food Network Smithfield terminated relationshi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>changes Macaire King propose education system ...</td>\n",
       "      <td>Macaire King help local Sen Greg Steube propos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>authors perspective aging time</td>\n",
       "      <td>author views aging time constant inevitable pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>educational qualifications Father Michael Ramos</td>\n",
       "      <td>Father Michael Ramos holds doctorate education...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>award player receive sportsmanship 201314</td>\n",
       "      <td>player received 2014 ITACissie Leary Award Spo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>features Fabiana Filippis shirts blouses</td>\n",
       "      <td>Fabiana Filippis shirts blouses easily matched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>qualifications required Director Care Center p...</td>\n",
       "      <td>qualifications required Director Care Center p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>third rider joining Pedercini team Phillip Island</td>\n",
       "      <td>third rider joining Pedercini team Phillip Isl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>done within 50 miles wheels placed vehicles</td>\n",
       "      <td>Wheels placed vehicles need inspected lugs rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Question  \\\n",
       "0    projected growth rate global economy 2014 acco...   \n",
       "1    terminated relationships Paula Deen scandalous...   \n",
       "2    changes Macaire King propose education system ...   \n",
       "3                       authors perspective aging time   \n",
       "4      educational qualifications Father Michael Ramos   \n",
       "..                                                 ...   \n",
       "995          award player receive sportsmanship 201314   \n",
       "996           features Fabiana Filippis shirts blouses   \n",
       "997  qualifications required Director Care Center p...   \n",
       "998  third rider joining Pedercini team Phillip Island   \n",
       "999        done within 50 miles wheels placed vehicles   \n",
       "\n",
       "                                                Answer  \n",
       "0    projected growth rate global economy 2014 acco...  \n",
       "1    Food Network Smithfield terminated relationshi...  \n",
       "2    Macaire King help local Sen Greg Steube propos...  \n",
       "3    author views aging time constant inevitable pr...  \n",
       "4    Father Michael Ramos holds doctorate education...  \n",
       "..                                                 ...  \n",
       "995  player received 2014 ITACissie Leary Award Spo...  \n",
       "996  Fabiana Filippis shirts blouses easily matched...  \n",
       "997  qualifications required Director Care Center p...  \n",
       "998  third rider joining Pedercini team Phillip Isl...  \n",
       "999  Wheels placed vehicles need inspected lugs rec...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test chat bot with general model or fine-tuning model of choice\n",
    "# *model* should include available OpenAI models for evaluation from link above\n",
    "model = \"gpt-3.5-turbo-0125\"\n",
    "evaluation_prompt = \"You are a highly intelligent AI trained to provide detailed and accurate answers to user questions by leveraging a knowledge base. Below is some background context followed by example questions and answers. Keep the answers short and concise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute function for testing model against unique samples\n",
    "result = evaluation(df_e, evaluation_prompt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Expected Answer</th>\n",
       "      <th>GPT Answer</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abraham Lincoln sixteenth President United States</td>\n",
       "      <td>Abraham Lincoln was the sixteenth President of...</td>\n",
       "      <td>Yes, Abraham Lincoln was the sixteenth Preside...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lincoln sign National Banking Act 1863</td>\n",
       "      <td>President Abraham Lincoln signed the National ...</td>\n",
       "      <td>Yes, Lincoln approved the National Banking Act...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mother die pneumonia</td>\n",
       "      <td>I am sorry to hear about your loss. Pneumonia ...</td>\n",
       "      <td>I'm sorry for the loss of your mother. If you ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many long Lincolns formal education</td>\n",
       "      <td>Abraham Lincoln had very little formal educati...</td>\n",
       "      <td>Lincoln's formal education consisted of 18 mon...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lincoln begin political career</td>\n",
       "      <td>Abraham Lincoln began his political career in ...</td>\n",
       "      <td>Lincoln began his political career in 1832 at ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>Wilson president American Political Science As...</td>\n",
       "      <td>Woodrow Wilson served as the President of the ...</td>\n",
       "      <td>Woodrow Wilson served as the president of the ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>cast ballot John Palmer presidential candidate...</td>\n",
       "      <td>John Palmer was a presidential candidate for t...</td>\n",
       "      <td>Yes, John Palmer cast a ballot for the preside...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>Wilson spend 1914 beginning 1917 trying keep A...</td>\n",
       "      <td>Wilson spent the years from 1914 to the beginn...</td>\n",
       "      <td>Wilson spent the period from 1914 to the begin...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>Wilson staunch opponent antisemitism sympathet...</td>\n",
       "      <td>Wilson was a staunch opponent of antisemitism ...</td>\n",
       "      <td>President Wilson was a staunch opponent of ant...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>happened 1917</td>\n",
       "      <td>In 1917, several significant events took place...</td>\n",
       "      <td>In 1917, the United States entered World War I.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Question  \\\n",
       "0    Abraham Lincoln sixteenth President United States   \n",
       "1               Lincoln sign National Banking Act 1863   \n",
       "2                                 mother die pneumonia   \n",
       "3                  many long Lincolns formal education   \n",
       "4                       Lincoln begin political career   \n",
       "..                                                 ...   \n",
       "913  Wilson president American Political Science As...   \n",
       "914  cast ballot John Palmer presidential candidate...   \n",
       "915  Wilson spend 1914 beginning 1917 trying keep A...   \n",
       "916  Wilson staunch opponent antisemitism sympathet...   \n",
       "917                                      happened 1917   \n",
       "\n",
       "                                       Expected Answer  \\\n",
       "0    Abraham Lincoln was the sixteenth President of...   \n",
       "1    President Abraham Lincoln signed the National ...   \n",
       "2    I am sorry to hear about your loss. Pneumonia ...   \n",
       "3    Abraham Lincoln had very little formal educati...   \n",
       "4    Abraham Lincoln began his political career in ...   \n",
       "..                                                 ...   \n",
       "913  Woodrow Wilson served as the President of the ...   \n",
       "914  John Palmer was a presidential candidate for t...   \n",
       "915  Wilson spent the years from 1914 to the beginn...   \n",
       "916  Wilson was a staunch opponent of antisemitism ...   \n",
       "917  In 1917, several significant events took place...   \n",
       "\n",
       "                                            GPT Answer Similarity  \n",
       "0    Yes, Abraham Lincoln was the sixteenth Preside...       None  \n",
       "1    Yes, Lincoln approved the National Banking Act...       None  \n",
       "2    I'm sorry for the loss of your mother. If you ...       None  \n",
       "3    Lincoln's formal education consisted of 18 mon...       None  \n",
       "4    Lincoln began his political career in 1832 at ...       None  \n",
       "..                                                 ...        ...  \n",
       "913  Woodrow Wilson served as the president of the ...       None  \n",
       "914  Yes, John Palmer cast a ballot for the preside...       None  \n",
       "915  Wilson spent the period from 1914 to the begin...       None  \n",
       "916  President Wilson was a staunch opponent of ant...       None  \n",
       "917    In 1917, the United States entered World War I.       None  \n",
       "\n",
       "[918 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanse\n",
    "result['Expected Answer'] = result['Expected Answer'].fillna(\"\").astype(str)\n",
    "result['GPT Answer'] = result['GPT Answer'].fillna(\"\").astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate embeddings for consine similarity \n",
    "dataset_embeddings = torch.stack([encode_text(answer) for answer in result['Expected Answer'].tolist()])\n",
    "gpt_embeddings = torch.stack([encode_text(answer) for answer in result['GPT Answer'].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarities: tensor([[ 1.,  1.,  1.,  ...,  1., -1.,  1.],\n",
      "        [-1., -1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        [ 1., -1.,  1.,  ..., -1.,  1.,  1.],\n",
      "        ...,\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1., -1.],\n",
      "        [-1., -1.,  1.,  ...,  1.,  1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = torch.nn.functional.cosine_similarity(dataset_embeddings, gpt_embeddings)\n",
    "print(\"Cosine Similarities:\", cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Similarity'] = cosine_sim\n",
    "threshold = 0.8\n",
    "correct = result[result['Similarity'] > threshold].shape[0]\n",
    "total = result.shape[0]\n",
    "accuracy = correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.479302832244"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.48%\n"
     ]
    }
   ],
   "source": [
    "# # cosine similarity accuracy\n",
    "print(f\"Accuracy: {accuracy * 1:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLEU metric result\n",
    "bleu_average(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE metric result\n",
    "rouge_average(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
