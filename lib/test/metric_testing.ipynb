{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rouge_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranslate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleu_score\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sentence_bleu\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrouge_score\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rouge_scorer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Predictor\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtagging\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rouge_score'"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence_bleu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m hypothesis \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElijah\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mborn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1689\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# AI Answer\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# BLEU Score Calculation\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m bleu_score \u001b[38;5;241m=\u001b[39m \u001b[43msentence_bleu\u001b[49m(reference, hypothesis, weights\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))  \u001b[38;5;66;03m# Unigram precision\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEU Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbleu_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sentence_bleu' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenized references and hypothesis\n",
    "reference = [['1689']]  # Dataset Answer\n",
    "hypothesis = ['Elijah', \"is\", 'born', 'in', '1689']  # AI Answer\n",
    "\n",
    "# BLEU Score Calculation\n",
    "bleu_score = sentence_bleu(reference, hypothesis, weights=(1, 0, 0, 0))  # Unigram precision\n",
    "print(f\"BLEU Score: {bleu_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1: Precision: 0.00, Recall: 0.00, F1: 0.00\n",
      "rouge2: Precision: 0.00, Recall: 0.00, F1: 0.00\n",
      "rougeL: Precision: 0.00, Recall: 0.00, F1: 0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Answers\n",
    "dataset_answer = \"Yes\"\n",
    "ai_answer = \"Elijah's hat is red\"\n",
    "\n",
    "# ROUGE Scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(dataset_answer, ai_answer)\n",
    "\n",
    "# Print Scores\n",
    "for metric, score in scores.items():\n",
    "    print(f\"{metric}: Precision: {score.precision:.2f}, Recall: {score.recall:.2f}, F1: {score.fmeasure:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": [
       "\u001b[?25l"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\elija\\VSCodeLocal\\Learning\\Projects\\NLP\\AgenticInformationRetrieval\\env\\lib\\site-packages\\rich\\live.py:229\n",
       ": UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\elija\\VSCodeLocal\\Learning\\Projects\\NLP\\AgenticInformationRetrieval\\env\\lib\\site-packages\\rich\\live.py:229\n",
       ": UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[?25h"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:allennlp.common.params:error loading _jsonnet (this is expected on Windows), treating C:\\Users\\elija\\AppData\\Local\\Temp\\tmpc0mcnaid\\config.json as plain json\n",
      "Downloading: 100%|██████████| 48.0/48.0 [00:00<?, ?B/s]\n",
      "Downloading: 100%|██████████| 570/570 [00:00<?, ?B/s] \n",
      "Downloading: 100%|██████████| 226k/226k [00:00<00:00, 3.99MB/s]\n",
      "Downloading: 100%|██████████| 455k/455k [00:00<00:00, 5.15MB/s]\n",
      "Downloading: 100%|██████████| 420M/420M [00:25<00:00, 17.2MB/s] \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING:allennlp.common.util:Spacy models 'en_core_web_sm' not found.  Downloading and installing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "AI Answer SRL: [{'verb': 'is', 'description': \"[ARG1: Elijah 's hat] [V: is] [ARG2: red]\", 'tags': ['B-ARG1', 'I-ARG1', 'I-ARG1', 'B-V', 'B-ARG2']}, {'verb': 'red', 'description': \"[ARG1: Elijah 's hat] is [V: red]\", 'tags': ['B-ARG1', 'I-ARG1', 'I-ARG1', 'O', 'B-V']}]\n",
      "Dataset Answer SRL: []\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "\n",
    "# Load Semantic Role Labeling model\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")\n",
    "\n",
    "# Perform SRL on AI and Dataset answers\n",
    "dataset_answer = \"Yes\"\n",
    "ai_answer = \"Elijah's hat is red\"\n",
    "\n",
    "# Predict SRL\n",
    "ai_result = predictor.predict(sentence=ai_answer)\n",
    "dataset_result = predictor.predict(sentence=dataset_answer)\n",
    "\n",
    "# Print Results\n",
    "print(\"AI Answer SRL:\", ai_result['verbs'])\n",
    "print(\"Dataset Answer SRL:\", dataset_result['verbs'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
